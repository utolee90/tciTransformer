{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a203aa7-438f-43a8-8e6b-f343069cb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# layer 비교하기 traffic 데이터를 가져오는 식으로 비교\n",
    "from layers.Embed import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f434db-3dea-47de-8ecf-834eac3855bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관련 패키지 불러오기\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers.Transformer_EncDec import Encoder, EncoderLayer\n",
    "from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894a1919-a9cf-498c-81ff-fd011faf3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 정리\n",
    "\n",
    "seq_len = 96 # c_in으로 \n",
    "label_len = 48\n",
    "pred_len = 48\n",
    "e_layers = 2\n",
    "d_layers = 1\n",
    "factor = 3\n",
    "enc_in = 321\n",
    "dec_in = 321\n",
    "d_model = 512\n",
    "batch_size = 32\n",
    "c_out = 321\n",
    "des = 'Exp'\n",
    "learning_rate = 0.001\n",
    "freq = 'h' # 입력빈도 - 세팅을 일일이 해야 하는 부분\n",
    "dropout = 0.1\n",
    "embed = 'timeF' # timeF, fixed, learned\n",
    "class_strategy = 'projection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac61804-6545-42a2-9369-c620026efdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_transformer_embedding_0 = DataEmbedding(seq_len, d_model, embed, freq, dropout) # DataEmbedding -> d_model이 반드시 짝수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f39df6-7cae-4cff-b270-e22fffa7be40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataEmbedding(\n",
       "  (value_embedding): TokenEmbedding(\n",
       "    (tokenConv): Conv1d(96, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n",
       "  )\n",
       "  (position_embedding): PositionalEmbedding()\n",
       "  (temporal_embedding): TimeFeatureEmbedding(\n",
       "    (embed): Linear(in_features=4, out_features=512, bias=False)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_transformer_embedding_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbcae55-052b-4758-90ec-a2e7c2484d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_transformer_embedding_1 = DataEmbedding_inverted(seq_len, d_model, embed, freq, dropout) # DataEmbedding -> d_model이 반드시 짝수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0ef8f2-65f2-4d43-a61b-25bd83631b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataEmbedding_inverted(\n",
       "  (value_embedding): Linear(in_features=96, out_features=512, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_transformer_embedding_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27ac8bd-7f6f-44e3-af2e-27420623f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_transformer_embedding_2 = DataEmbedding_inverted_TCN(seq_len, d_model, embed, freq, dropout) # DataEmbedding -> d_model이 반드시 짝수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20290980-836a-4e23-880d-cff8998538ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataEmbedding_inverted_TCN(\n",
       "  (value_embedding): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv1): Conv1d(96, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(96, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (downsample): Conv1d(96, 512, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): TemporalBlock(\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): TemporalBlock(\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_transformer_embedding_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23355f27-f8d4-486c-af91-bc413d427d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(batch_size, enc_in, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33871b3d-668e-4426-9327-0a951b9ec3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1011,  1.4886, -0.3352,  ..., -0.2612,  0.1785, -1.0775],\n",
       "         [ 0.4506,  0.6834, -0.2184,  ...,  0.3832, -2.1318, -0.0323],\n",
       "         [-1.1829, -0.5971, -0.9591,  ..., -1.8489,  0.6979,  1.5031],\n",
       "         ...,\n",
       "         [-1.7059, -0.0709,  0.4251,  ...,  1.0579,  0.5637,  0.1422],\n",
       "         [ 0.6427,  0.4494,  0.4432,  ...,  0.3454, -0.2712, -0.5893],\n",
       "         [ 3.2618,  0.8585,  0.2424,  ..., -0.3707, -1.5716, -0.2592]],\n",
       "\n",
       "        [[-0.1825,  1.2955,  0.0864,  ...,  0.3704,  1.2158, -0.3402],\n",
       "         [ 0.2949,  0.3406,  0.5457,  ...,  0.6796, -0.0885, -1.6989],\n",
       "         [ 1.1521,  1.0768, -0.8525,  ...,  0.4093,  1.3842, -1.7188],\n",
       "         ...,\n",
       "         [-0.5904, -0.0937, -1.6161,  ...,  2.0701, -0.1695,  1.2379],\n",
       "         [ 1.6437,  0.6973, -2.4861,  ..., -1.1352,  0.5089, -0.9791],\n",
       "         [ 0.2952, -0.9201, -0.0307,  ...,  0.1292,  0.3065,  0.5407]],\n",
       "\n",
       "        [[ 0.6436,  0.4255, -0.7122,  ...,  1.1663,  0.7979,  0.4631],\n",
       "         [ 0.1742,  0.7437, -0.0831,  ...,  0.9314, -0.5730,  0.1663],\n",
       "         [ 1.3895, -0.3796,  0.6100,  ...,  1.3804,  1.8861, -0.5990],\n",
       "         ...,\n",
       "         [ 0.7360, -1.0580,  0.4696,  ...,  0.8495,  0.1704,  1.3206],\n",
       "         [ 0.5472, -0.4416,  0.3343,  ..., -0.1755, -0.1350, -0.6969],\n",
       "         [-0.9705, -3.3562,  0.1860,  ..., -0.1056,  0.1223,  0.1247]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.8496, -0.2488,  1.4963,  ..., -0.2874, -0.2583,  2.0754],\n",
       "         [-0.4477,  0.6144, -0.6604,  ...,  0.4841,  0.2403, -0.2783],\n",
       "         [ 1.0495, -1.5837, -0.0269,  ...,  0.0295, -0.6497, -1.4143],\n",
       "         ...,\n",
       "         [-1.3282,  1.4078, -0.4793,  ..., -0.2730, -0.0780, -0.4625],\n",
       "         [ 0.3956, -0.2750,  1.6282,  ...,  0.7101,  0.1834,  1.7089],\n",
       "         [ 0.0179,  1.0570,  0.2498,  ..., -0.6224,  0.9773, -0.2069]],\n",
       "\n",
       "        [[ 1.5330, -0.1715, -0.4794,  ...,  1.5484,  1.9514,  0.3624],\n",
       "         [ 0.7301, -0.3919, -1.2176,  ..., -1.0575,  1.3173,  1.5362],\n",
       "         [ 1.7842, -1.0514, -0.6894,  ...,  0.7580,  0.6370,  1.0129],\n",
       "         ...,\n",
       "         [ 2.4851,  1.1009, -0.0150,  ..., -0.1495, -0.1467, -0.2392],\n",
       "         [ 0.7372, -0.1183,  0.1430,  ...,  1.0084, -0.1894,  0.2344],\n",
       "         [ 0.4615, -0.0547,  1.2786,  ..., -0.5585,  0.2625, -0.9480]],\n",
       "\n",
       "        [[-1.7857, -0.0461,  0.8564,  ...,  0.9721, -0.6153,  0.6409],\n",
       "         [-0.4277, -0.2049,  0.5854,  ..., -1.1097, -0.0273, -0.2086],\n",
       "         [ 1.2105, -0.5174, -0.6817,  ..., -1.1108,  0.8386, -1.4985],\n",
       "         ...,\n",
       "         [-0.1649,  0.3380,  1.9209,  ..., -0.8081, -1.1455, -1.5213],\n",
       "         [-1.4658,  0.4397, -0.4927,  ...,  0.1265,  1.2557,  0.6269],\n",
       "         [ 2.8241, -1.7446,  0.3672,  ...,  0.4820, -1.4014,  0.8764]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd861625-8b49-464a-93bd-5f73783ae99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 321, 96])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d70b4794-5dcf-4ae3-8ecc-1f8d77a81c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input_0 = dummy_input.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9de4cfc-1230-4ee9-b05c-7b589dc92ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_0 = enc_transformer_embedding_0(dummy_input, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "074433d9-3fc0-4984-91ca-f484a122231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 321, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "461e83c1-bd26-4971-899f-100f596652ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1 = enc_transformer_embedding_1(dummy_input_0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b6eb1be-8eba-41bc-92cb-6ed6c83b451e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7585,  1.5463,  0.9794,  ...,  0.7797,  0.0665,  0.0000],\n",
       "         [ 0.5697,  0.6630,  0.0000,  ..., -0.6504,  0.0980,  0.4349],\n",
       "         [-0.7135,  0.2651, -0.0930,  ..., -1.1551, -0.6556,  0.0842],\n",
       "         ...,\n",
       "         [ 1.1376,  0.8615,  0.5159,  ..., -0.4196, -0.3769, -0.3308],\n",
       "         [ 0.0606,  0.2590,  0.2322,  ..., -0.0000, -0.0419,  0.1631],\n",
       "         [-0.6893,  0.0000,  0.2926,  ..., -0.1034, -1.0699, -0.1834]],\n",
       "\n",
       "        [[-0.1089,  0.2612, -1.5831,  ...,  1.4222,  0.0000,  0.3634],\n",
       "         [ 0.1111, -0.4005, -0.2421,  ...,  0.2801,  0.0785,  0.6096],\n",
       "         [ 0.8069,  0.6305, -0.5333,  ..., -0.3468,  0.4131,  1.2825],\n",
       "         ...,\n",
       "         [-0.1251,  0.7564, -1.1507,  ..., -0.7445, -1.0885,  0.3749],\n",
       "         [-0.2715, -0.0000, -1.0706,  ...,  0.8989,  0.6929, -0.7381],\n",
       "         [-0.3967, -0.1841,  0.0000,  ...,  0.6414,  0.6907, -0.6895]],\n",
       "\n",
       "        [[ 0.0179, -0.1070, -0.7489,  ...,  0.5237, -1.0359, -1.3179],\n",
       "         [ 0.1591,  0.2837,  0.3510,  ..., -0.0000, -0.6275, -0.8442],\n",
       "         [-0.4203, -0.0397, -0.0506,  ..., -0.0000, -0.4725, -0.0000],\n",
       "         ...,\n",
       "         [-1.6119,  0.4047, -1.3748,  ..., -0.2781, -0.8867, -1.0284],\n",
       "         [ 0.6586,  0.7006, -0.1323,  ..., -0.6865, -0.4750,  1.3034],\n",
       "         [ 0.0000, -0.1120,  0.0000,  ..., -0.3162, -1.1646, -0.2919]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.2009,  0.0000,  0.4639,  ...,  0.2638,  0.9995, -0.1742],\n",
       "         [-0.7296, -0.0000, -1.1520,  ..., -0.3104, -1.4347, -0.2094],\n",
       "         [ 0.0360,  0.2491,  0.2524,  ...,  0.0108, -0.6145, -0.0000],\n",
       "         ...,\n",
       "         [-0.0000, -0.6707, -1.1606,  ..., -0.1580, -0.1010,  0.2255],\n",
       "         [-0.6059, -0.4121,  0.1527,  ...,  0.1544,  0.0285,  0.1492],\n",
       "         [ 0.4993,  0.4799,  0.0684,  ..., -0.0000, -0.9573, -0.7425]],\n",
       "\n",
       "        [[-0.3585, -0.2902, -0.7240,  ...,  0.6704, -0.8176, -0.0000],\n",
       "         [-0.6816, -0.2559,  0.2135,  ..., -0.7788, -0.2421, -0.7803],\n",
       "         [-0.1495,  0.2156,  0.7152,  ...,  0.5092, -0.1940, -0.9124],\n",
       "         ...,\n",
       "         [-0.0000, -0.2185,  0.6501,  ...,  0.4896,  0.3689, -0.0115],\n",
       "         [-0.5613,  1.5163, -0.4175,  ...,  0.0179, -0.2141,  0.6191],\n",
       "         [ 0.1333,  0.3228,  1.0360,  ..., -0.0000, -0.3086, -0.7236]],\n",
       "\n",
       "        [[ 0.8496, -0.4515,  1.5372,  ..., -0.1322,  1.0049,  0.6030],\n",
       "         [-0.2815, -0.3041,  0.3467,  ..., -0.4904, -0.1001, -0.5654],\n",
       "         [-0.3100, -0.4023,  0.3507,  ...,  0.6583,  0.0537,  0.0650],\n",
       "         ...,\n",
       "         [ 0.2842, -2.0027,  0.8387,  ...,  1.3151,  1.2883,  0.6477],\n",
       "         [-0.3141,  0.7498, -0.2255,  ..., -0.1694, -0.4348, -0.6121],\n",
       "         [-1.2671,  1.2138, -0.0528,  ...,  1.3217,  0.2174,  0.2993]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f78f607b-eae7-450e-93a0-7455e3a5dedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 321, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a0b9c58-05d9-481c-b440-955017bbfb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 321, 96])\n"
     ]
    }
   ],
   "source": [
    "output_2 = enc_transformer_embedding_2(dummy_input_0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d66a7ba-7ef2-4656-851e-f5af14262116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 96, 321])\n"
     ]
    }
   ],
   "source": [
    "output_20 = enc_transformer_embedding_2(dummy_input, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8406b1c4-268e-46e8-a12d-8d5dd8a01d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_block1 = TemporalBlock1(96, 512, 2,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "143ba540-d642-4fa7-bbe6-ad4016aefdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_temporal = temporal_block1(dummy_input_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b9472e-49bd-4c60-b833-156617747cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 321])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_temporal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5a9f873-c48b-4561-a74a-7268a7c29dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [512, 96, 2], expected input[32, 321, 96] to have 96 channels, but got 321 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output_temporal \u001b[38;5;241m=\u001b[39m \u001b[43mtemporal_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\test\\tciTransformer\\layers\\Embed.py:173\u001b[0m, in \u001b[0;36mTemporalBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    171\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# 추가\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# print(\"Input size:\", x.size())\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# print(\"Output size after conv layers:\", out.size())\u001b[39;00m\n\u001b[0;32m    175\u001b[0m res \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [512, 96, 2], expected input[32, 321, 96] to have 96 channels, but got 321 channels instead"
     ]
    }
   ],
   "source": [
    "output_temporal = temporal_block(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92a53184-da2b-465f-b1f2-f54bfee6de97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.9887e-02, 1.2409e-01, 1.7761e-01,  ..., 6.5624e-02,\n",
       "          9.7772e-03, 0.0000e+00],\n",
       "         [0.0000e+00, 2.5196e-01, 1.3163e-02,  ..., 4.3740e-02,\n",
       "          1.2417e-02, 2.1450e-02],\n",
       "         [1.3100e-01, 1.3373e-01, 5.9980e-02,  ..., 0.0000e+00,\n",
       "          7.0686e-03, 0.0000e+00],\n",
       "         ...,\n",
       "         [7.1469e-02, 0.0000e+00, 8.3666e-02,  ..., 3.7311e-03,\n",
       "          1.3744e-02, 3.9985e-03],\n",
       "         [0.0000e+00, 0.0000e+00, 1.4286e-02,  ..., 1.8574e-01,\n",
       "          3.7800e-02, 0.0000e+00],\n",
       "         [1.3890e-01, 8.2674e-02, 1.6861e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 2.3342e-01, 1.2673e-01,  ..., 1.3788e-01,\n",
       "          0.0000e+00, 7.7979e-03],\n",
       "         [9.6090e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          8.7233e-03, 5.6930e-02],\n",
       "         [1.1677e-01, 0.0000e+00, 5.1605e-02,  ..., 3.8304e-02,\n",
       "          2.1290e-02, 0.0000e+00],\n",
       "         ...,\n",
       "         [1.2013e-01, 2.0939e-01, 8.7630e-02,  ..., 0.0000e+00,\n",
       "          9.2156e-03, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.5371e-01,\n",
       "          1.5102e-02, 1.2320e-03],\n",
       "         [0.0000e+00, 5.8224e-02, 7.4584e-03,  ..., 1.5592e-01,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[3.2656e-02, 0.0000e+00, 1.6147e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 2.8934e-02],\n",
       "         [1.8390e-03, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          3.8491e-02, 4.5558e-03],\n",
       "         [1.5641e-03, 0.0000e+00, 9.0137e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 5.5691e-02, 0.0000e+00,  ..., 6.0816e-02,\n",
       "          5.5804e-03, 1.0761e-02],\n",
       "         [1.1445e-01, 2.0824e-01, 9.3479e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [4.4372e-02, 2.2233e-01, 1.6051e-02,  ..., 9.0108e-02,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.1463e-02, 1.3402e-01, 2.1661e-01,  ..., 1.0277e-01,\n",
       "          1.7807e-02, 0.0000e+00],\n",
       "         [2.3067e-03, 1.0797e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 3.0936e-02],\n",
       "         [5.8624e-02, 8.8356e-02, 8.1852e-02,  ..., 1.1971e-01,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 1.8841e-01, 0.0000e+00,  ..., 5.4055e-02,\n",
       "          0.0000e+00, 9.2702e-03],\n",
       "         [7.9129e-02, 8.4879e-02, 1.8890e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.2054e-02],\n",
       "         [1.5641e-01, 7.5141e-02, 6.9703e-02,  ..., 1.8297e-01,\n",
       "          3.3900e-02, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 1.8477e-02, 1.1964e-01,  ..., 0.0000e+00,\n",
       "          1.8517e-02, 1.0114e-02],\n",
       "         [3.7742e-02, 1.6079e-01, 0.0000e+00,  ..., 6.8018e-02,\n",
       "          8.5941e-02, 1.3713e-02],\n",
       "         [1.2066e-01, 1.9316e-01, 5.3809e-02,  ..., 1.6909e-01,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 5.9433e-03, 0.0000e+00,  ..., 1.6844e-01,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [9.6041e-02, 9.8416e-02, 2.0964e-01,  ..., 2.1235e-01,\n",
       "          0.0000e+00, 3.1319e-03],\n",
       "         [1.7988e-01, 0.0000e+00, 0.0000e+00,  ..., 1.4507e-01,\n",
       "          1.2545e-02, 0.0000e+00]],\n",
       "\n",
       "        [[1.2328e-01, 9.9247e-02, 9.6636e-03,  ..., 0.0000e+00,\n",
       "          1.1598e-02, 8.7065e-03],\n",
       "         [1.1330e-01, 0.0000e+00, 0.0000e+00,  ..., 1.9567e-03,\n",
       "          0.0000e+00, 4.2027e-02],\n",
       "         [2.1759e-01, 2.8512e-01, 2.7672e-02,  ..., 2.8989e-02,\n",
       "          4.0114e-03, 2.0189e-02],\n",
       "         ...,\n",
       "         [5.6258e-02, 1.3139e-01, 2.5522e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 3.7916e-03],\n",
       "         [5.9384e-02, 5.0612e-05, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          4.0677e-02, 1.7014e-02],\n",
       "         [0.0000e+00, 1.3840e-01, 4.7900e-02,  ..., 8.4967e-02,\n",
       "          0.0000e+00, 0.0000e+00]]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e4ddf016-17ce-4c6f-a2e5-93fa263a9ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 98])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_temporal.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2a3813c-71e7-43bd-8d2e-b82fe01c3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_conv_net = TemporalConvNet1(96, [512, 512, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b50ea456-c3bb-4ce7-b7a1-b72bdb2eaa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_temporal_conv_net = temporal_conv_net(dummy_input_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0dda9f0e-c151-4cb0-a3e9-d46b161f054c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0249, 0.0278, 0.0253,  ..., 0.0000, 0.0185, 0.0000],\n",
       "         [0.0203, 0.0000, 0.1856,  ..., 0.0029, 0.0084, 0.0009],\n",
       "         [0.0361, 0.1856, 0.0498,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0266, 0.0214, 0.1779,  ..., 0.0000, 0.0102, 0.0115],\n",
       "         [0.1257, 0.0316, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.1381, 0.0740, 0.1175,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.1560, 0.0338, 0.0129,  ..., 0.0168, 0.0184, 0.0190],\n",
       "         [0.0000, 0.0776, 0.2084,  ..., 0.0044, 0.0059, 0.0027],\n",
       "         [0.0862, 0.0733, 0.1529,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0796, 0.1283, 0.2700,  ..., 0.0071, 0.0089, 0.0077],\n",
       "         [0.0000, 0.0000, 0.0619,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0028, 0.0601, 0.1972,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.1644, 0.0188, 0.0992,  ..., 0.0239, 0.0170, 0.0170],\n",
       "         [0.1283, 0.0000, 0.0668,  ..., 0.0013, 0.0049, 0.0030],\n",
       "         [0.3076, 0.1029, 0.0309,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0929, 0.1662, 0.1383,  ..., 0.0069, 0.0067, 0.0119],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0048, 0.0000, 0.1013,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0301, 0.1603, 0.0735,  ..., 0.0177, 0.0160, 0.0154],\n",
       "         [0.0000, 0.0897, 0.0274,  ..., 0.0030, 0.0003, 0.0063],\n",
       "         [0.0782, 0.0761, 0.0397,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1265, 0.0958, 0.1075,  ..., 0.0048, 0.0096, 0.0064],\n",
       "         [0.0000, 0.0000, 0.1094,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.1054, 0.0000, 0.1807,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0982, 0.0430, 0.0694,  ..., 0.0221, 0.0162, 0.0174],\n",
       "         [0.0000, 0.0138, 0.0016,  ..., 0.0000, 0.0067, 0.0000],\n",
       "         [0.0691, 0.0786, 0.2445,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1842, 0.1912, 0.2476,  ..., 0.0000, 0.0097, 0.0088],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.2036,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0125, 0.0000, 0.1155,  ..., 0.0177, 0.0146, 0.0161],\n",
       "         [0.1921, 0.0030, 0.0165,  ..., 0.0000, 0.0071, 0.0052],\n",
       "         [0.0315, 0.1361, 0.1899,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.1194, 0.0089, 0.1692,  ..., 0.0117, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0216,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0371, 0.2362, 0.2558,  ..., 0.0000, 0.0000, 0.0000]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_temporal_conv_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe8e0e88-d093-4c94-97cb-495b82e520ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 321])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_temporal_conv_net.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6356dbd-72ba-4b0d-a292-511d13c9a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn_res = TCN(96, 48, [512]*3, 2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b852607b-0676-4134-9bf9-e50089e0fafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCN(\n",
       "  (tcn): TemporalConvNet1(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock1(\n",
       "        (conv1): Conv1d(96, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(96, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (downsample): Conv1d(96, 512, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): TemporalBlock1(\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): TemporalBlock1(\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (1): Chomp1d()\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (5): Chomp1d()\n",
       "          (6): ReLU()\n",
       "          (7): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcn_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a134796-7612-40e7-b3d3-9271a63da201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8015, -3.6434, -3.8423,  ..., -3.7777, -3.9636, -3.9175],\n",
       "        [-3.8019, -3.6425, -3.8388,  ..., -3.8389, -4.0670, -3.8083],\n",
       "        [-3.9327, -3.5663, -3.6373,  ..., -3.6391, -4.0712, -3.9037],\n",
       "        ...,\n",
       "        [-3.7439, -3.7151, -3.6944,  ..., -3.8529, -3.9892, -4.0773],\n",
       "        [-3.8571, -3.6266, -3.7591,  ..., -3.8624, -3.8717, -3.8816],\n",
       "        [-3.6148, -3.7586, -3.8465,  ..., -3.7602, -3.9648, -4.0417]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcn_res(dummy_input_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27f57fab-e1a3-4a1b-b588-811a05905cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 48])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcn_res(dummy_input_0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d688f1b-8369-40ee-afe3-92d518d64951",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_conv_net = TemporalConvNet(seq_len, [d_model]*3, 2, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e4d182e-1cdf-4249-9efb-7038c2b965e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 96, 321]) 96\n",
      "Input size: torch.Size([32, 96, 321])\n",
      "torch.Size([32, 512, 323]) 512\n",
      "Input size: torch.Size([32, 512, 323])\n",
      "torch.Size([32, 512, 327]) 512\n",
      "Input size: torch.Size([32, 512, 327])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512, 335])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_conv_net(dummy_input_0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f64f5b68-8ec6-4559-80b8-83a28d8cb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_transformer_embedding_2 = DataEmbedding_inverted_TCN(seq_len, d_model, embed, freq, dropout) # DataEmbedding -> d_model이 반드시 짝수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8e52a85-4ee4-4b45-8e8a-11fb29c487be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataEmbedding_inverted_TCN(\n",
       "  (value_embedding): TemporalConvNet(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlock(\n",
       "        (conv1): Conv1d(96, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(96, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (downsample): Conv1d(96, 512, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): TemporalBlock(\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): TemporalBlock(\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (chomp1): Chomp1d()\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (chomp2): Chomp1d()\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_transformer_embedding_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed979f44-929e-4925-8f22-996006ac49cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 321, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1124,  1.6540, -0.3725,  ..., -0.0000,  0.1983, -1.1973],\n",
       "         [ 0.5006,  0.7594, -0.2427,  ...,  0.4258, -0.0000, -0.0359],\n",
       "         [-1.3144, -0.6634, -1.0657,  ..., -2.0543,  0.7755,  1.6701],\n",
       "         ...,\n",
       "         [-1.8955, -0.0788,  0.4723,  ...,  1.1754,  0.0000,  0.1580],\n",
       "         [ 0.7141,  0.4993,  0.4925,  ...,  0.3838, -0.3013, -0.6548],\n",
       "         [ 3.6243,  0.9539,  0.2693,  ..., -0.4118, -1.7462, -0.2880]],\n",
       "\n",
       "        [[-0.2028,  1.4394,  0.0960,  ...,  0.4116,  1.3508, -0.3780],\n",
       "         [ 0.3277,  0.3785,  0.6064,  ...,  0.7551, -0.0983, -1.8877],\n",
       "         [ 1.2801,  1.1964, -0.9473,  ...,  0.4548,  1.5380, -1.9097],\n",
       "         ...,\n",
       "         [-0.6560, -0.1041, -0.0000,  ...,  2.3001, -0.1883,  1.3754],\n",
       "         [ 0.0000,  0.7748, -0.0000,  ..., -1.2613,  0.5654, -1.0879],\n",
       "         [ 0.3280, -1.0223, -0.0341,  ...,  0.1436,  0.3406,  0.6007]],\n",
       "\n",
       "        [[ 0.0000,  0.4728, -0.7913,  ...,  1.2959,  0.8865,  0.0000],\n",
       "         [ 0.1936,  0.8263, -0.0924,  ...,  1.0349, -0.6366,  0.1848],\n",
       "         [ 1.5439, -0.4217,  0.6778,  ...,  0.0000,  2.0957, -0.6656],\n",
       "         ...,\n",
       "         [ 0.8177, -1.1756,  0.5218,  ...,  0.9439,  0.1894,  1.4673],\n",
       "         [ 0.6080, -0.0000,  0.3714,  ..., -0.1950, -0.1500, -0.7743],\n",
       "         [-1.0784, -3.7291,  0.2067,  ..., -0.1174,  0.1358,  0.1386]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.9440, -0.2765,  1.6626,  ..., -0.3193, -0.2870,  2.3060],\n",
       "         [-0.4974,  0.6826, -0.7338,  ...,  0.5379,  0.2670, -0.3092],\n",
       "         [ 1.1661, -1.7597, -0.0299,  ...,  0.0328, -0.7219, -1.5714],\n",
       "         ...,\n",
       "         [-1.4758,  1.5642, -0.5326,  ..., -0.0000, -0.0867, -0.5139],\n",
       "         [ 0.4396, -0.3056,  1.8092,  ...,  0.7890,  0.2038,  1.8988],\n",
       "         [ 0.0199,  1.1744,  0.0000,  ..., -0.6915,  1.0859, -0.2299]],\n",
       "\n",
       "        [[ 1.7033, -0.1906, -0.5326,  ...,  1.7205,  2.1682,  0.4027],\n",
       "         [ 0.8112, -0.4354, -1.3529,  ..., -1.1750,  1.4636,  1.7069],\n",
       "         [ 1.9825, -1.1682, -0.7660,  ...,  0.8423,  0.7078,  1.1254],\n",
       "         ...,\n",
       "         [ 2.7612,  1.2233, -0.0000,  ..., -0.1661, -0.1630, -0.2657],\n",
       "         [ 0.8191, -0.1314,  0.1589,  ...,  1.1204, -0.2105,  0.2605],\n",
       "         [ 0.5128, -0.0608,  1.4207,  ..., -0.6205,  0.2917, -1.0533]],\n",
       "\n",
       "        [[-1.9842, -0.0512,  0.9516,  ...,  1.0801, -0.0000,  0.7122],\n",
       "         [-0.4753, -0.2277,  0.6504,  ..., -1.2330, -0.0304, -0.2318],\n",
       "         [ 1.3450, -0.5749, -0.7574,  ..., -1.2342,  0.9318, -1.6650],\n",
       "         ...,\n",
       "         [-0.1833,  0.3756,  2.1343,  ..., -0.8979, -1.2728, -0.0000],\n",
       "         [-1.6286,  0.0000, -0.5474,  ...,  0.1405,  1.3952,  0.6966],\n",
       "         [ 0.0000, -1.9385,  0.4080,  ...,  0.5356, -1.5572,  0.9738]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_transformer_embedding_2(dummy_input_0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b8cfb-e8fa-4a01-a7ae-89af7a96eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TemporalConvNet(c_in, [d_model]*3) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
