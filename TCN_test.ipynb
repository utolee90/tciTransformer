{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb70529b-6169-49e9-bb61-3ba5cffcf383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# layer 비교하기 traffic 데이터를 가져오는 식으로 비교\n",
    "from layers.Embed import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers.Transformer_EncDec import Encoder, EncoderLayer\n",
    "from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44b3e282-cd60-4b33-a4c1-ef8ba934f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temporal_conv_new = TemporalConvNetNew(96, [48]*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c14a8327-0683-4632-9b30-1777ca7d7e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_block_new = TemporalBlockNew(96, 48, 2, 1, 1, 1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8b1f856-5bd1-4903-acd8-7d130013d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn_sample = TCN(96, 64, [48]*3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5e6bc6c-a614-4adb-93cb-478588a30325",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.randn(2, 96, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0252509-2e50-4467-bed0-6d1207d98ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tcn = tcn_sample(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ae312e-3108-4cb3-af36-1894593171ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tcn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa0df693-d683-4c6c-b2f4-354415f82e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Solar, Dataset_PEMS, \\\n",
    "    Dataset_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79f553c3-498b-4a45-a304-656fbf7bcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a14cf8a1-7b0d-42e8-9e84-f8a1e9d6b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_set = Dataset_Custom(\n",
    "    root_path = './dataset/traffic/',\n",
    "    data_path = 'traffic.csv',\n",
    "    flag= 'train',\n",
    "    size= [96, 862, 48],\n",
    "    features = 'M',\n",
    "    target = 'OT',\n",
    "    timeenc = 1,\n",
    "    freq='h'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd919350-e296-4ada-ad70-36ec5fdb26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    datas_set,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=10,\n",
    "    drop_last = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f58a52c3-02d9-4e6b-8ed6-00c22940bddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__read_data__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_is_protocol',\n",
       " 'data_path',\n",
       " 'data_stamp',\n",
       " 'data_x',\n",
       " 'data_y',\n",
       " 'features',\n",
       " 'freq',\n",
       " 'inverse_transform',\n",
       " 'label_len',\n",
       " 'pred_len',\n",
       " 'root_path',\n",
       " 'scale',\n",
       " 'scaler',\n",
       " 'seq_len',\n",
       " 'set_type',\n",
       " 'target',\n",
       " 'timeenc']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datas_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e82e70e-8fbd-40b2-8753-73a5516d0fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0daa61c5-6ec1-4081-ad47-cf8a6e3323dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TCN(96, 48, [862]*3, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd7d3d-4d68-422e-b98f-459e2aee0d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e7671dd-c027-4ba2-8d74-522fe67838d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCN(\n",
       "  (tcn): TemporalConvNetNew(\n",
       "    (network): Sequential(\n",
       "      (0): TemporalBlockNew(\n",
       "        (conv1): Conv1d(96, 862, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(96, 862, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (downsample): Conv1d(96, 862, kernel_size=(1,), stride=(1,))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): TemporalBlockNew(\n",
       "        (conv1): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): TemporalBlockNew(\n",
       "        (conv1): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (relu1): ReLU()\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (conv2): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (relu2): ReLU()\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (net): Sequential(\n",
       "          (0): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (1): ReLU()\n",
       "          (2): Dropout(p=0.2, inplace=False)\n",
       "          (3): Conv1d(862, 862, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (4): ReLU()\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=862, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9848efc6-f5cd-402f-8583-7c2ecc593a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.randn(32, 96, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0de097aa-4db6-4c24-9df6-b343c03da1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12280, 862)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas_set.data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "171b75f1-60a3-4f7a-a3e5-a24fdcf8d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ab4ea8ad-6570-4628-95ed-c27d7e15cf5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 48])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7cea66c-c9f8-41c1-b775-d989851c0c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.9155, -3.8848, -3.8742, -3.8775, -3.8594, -3.8667, -3.8491, -3.8309,\n",
       "        -3.8454, -3.8702, -3.8828, -3.8559, -3.8646, -3.8640, -3.9193, -3.8508,\n",
       "        -3.8587, -3.8605, -3.8757, -3.8337, -3.8943, -3.8446, -3.8689, -3.8793,\n",
       "        -3.8998, -3.8936, -3.8846, -3.8687, -3.8616, -3.8936, -3.8455, -3.8683,\n",
       "        -3.8629, -3.8768, -3.8542, -3.8927, -3.8813, -3.8745, -3.8893, -3.8872,\n",
       "        -3.8710, -3.8548, -3.8626, -3.8931, -3.8674, -3.8695, -3.8800, -3.8660],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6842d507-42b7-4225-b956-a6fe436e1984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "72ed5d6d-f4f3-4455-8071-3a21ee794661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eadb595b-c791-4b97-8b73-a370e954e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0842b273-0c42-4234-9ae3-8f941f34b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fca59a0b-55d9-44ed-9a5b-b0395d354976",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_now = time.time()\n",
    "\n",
    "train_steps = len(data_loader)\n",
    "early_stopping = EarlyStopping(patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6d404d3-6e8d-4762-8259-5f8261d377c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_time = time.time()\n",
    "iter_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fecc9463-e619-485e-9e53-aa5f19716fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ad503fa3-214e-40c1-9a5a-6d345385d475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 171, in collate_numpy_array_fn\n    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [0, 862] at entry 0 and [910, 862] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x_mark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y_mark\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43miter_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_optim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 171, in collate_numpy_array_fn\n    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 162, in collate_tensor_fn\n    return torch.stack(batch, 0, out=out)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: stack expects each tensor to be equal size, but got [0, 862] at entry 0 and [910, 862] at entry 1\n"
     ]
    }
   ],
   "source": [
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(data_loader):\n",
    "    iter_count += 1\n",
    "    model_optim.zero_grad()\n",
    "    batch_x = batch_x.float().cpu()\n",
    "    batch_y = batch_y.float().cpu()\n",
    "    \n",
    "    # print(batch_x, batch_y)\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().cpu()\n",
    "    batch_y_mark = batch_y_mark.float().cpu()\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -48:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :862, :], dec_inp], dim=1).float().cpu()\n",
    "\n",
    "    outputs =model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "\n",
    "    f_dim = 0\n",
    "    outputs = outputs[:, -48:, f_dim:]\n",
    "    batch_y = batch_y[:, -48:, f_dim:].to(0)\n",
    "    \n",
    "    pred = outputs.detach().cpu()\n",
    "    true = batch_y.detach().cpu()\n",
    "\n",
    "    loss = criterion(pred, true)\n",
    "\n",
    "    print(f\"{i}번째 결과\")\n",
    "    print(loss.item())\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    if 'PEMS' in self.args.data or 'Solar' in self.args.data:\n",
    "        batch_x_mark = None\n",
    "        batch_y_mark = None\n",
    "    else:\n",
    "        batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "    # decoder input\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "    dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "\n",
    "    # encoder - decoder\n",
    "    if self.args.use_amp:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            if self.args.output_attention:\n",
    "                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "            else:\n",
    "                outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "            batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            train_loss.append(loss.item())\n",
    "    else:\n",
    "        if self.args.output_attention:\n",
    "            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "        else:\n",
    "            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "        f_dim = -1 if self.args.features == 'MS' else 0\n",
    "        outputs = outputs[:, -self.args.pred_len:, f_dim:]\n",
    "        batch_y = batch_y[:, -self.args.pred_len:, f_dim:].to(self.device)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "        speed = (time.time() - time_now) / iter_count\n",
    "        left_time = speed * ((self.args.train_epochs - epoch) * train_steps - i)\n",
    "        print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "        iter_count = 0\n",
    "        time_now = time.time()\n",
    "\n",
    "    if self.args.use_amp:\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(model_optim)\n",
    "        scaler.update()\n",
    "    else:\n",
    "        loss.backward()\n",
    "        model_optim.step()\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "276c4d64-d72b-41bc-8468-23d06ad93261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.1024, -0.0676,  0.9625,  ...,  0.6017,  1.5872,  1.9987],\n",
      "         [ 0.0828, -0.1835, -0.5140,  ...,  0.6060,  1.4549,  1.8046],\n",
      "         [ 0.1024, -0.1876, -0.5042,  ...,  0.6060,  1.0713,  1.7989],\n",
      "         ...,\n",
      "         [ 0.2021,  0.2519,  1.8446,  ...,  0.3309,  1.7128,  1.8731],\n",
      "         [ 0.1677,  0.3780,  1.4893,  ...,  0.5157,  1.6136,  2.1014],\n",
      "         [ 0.2674,  0.1339,  1.5984,  ...,  0.6490,  1.6070,  2.2042]],\n",
      "\n",
      "        [[ 1.7394,  1.0026,  0.7027,  ...,  0.4383,  0.8001, -0.2100],\n",
      "         [ 5.4432,  4.0584,  0.2408,  ...,  1.0274,  1.1308,  0.5205],\n",
      "         [ 3.8127,  5.0187,  1.4526,  ...,  1.3154,  1.2432,  0.8116],\n",
      "         ...,\n",
      "         [-0.7161, -0.7919, -1.1107,  ..., -0.7655, -1.4354, -1.4143],\n",
      "         [-0.7047, -0.7328, -1.0359,  ..., -0.7698, -1.3230, -1.4314],\n",
      "         [-0.6410, -0.4846, -0.9036,  ..., -0.5591, -1.1246, -1.2602]],\n",
      "\n",
      "        [[-0.7194, -0.7267, -1.0617,  ..., -0.7397, -1.3693, -1.4200],\n",
      "         [-0.6916, -0.6271, -0.9195,  ..., -0.5634, -1.1047, -1.2944],\n",
      "         [-0.6785, -0.5416, -0.8436,  ..., -0.2023, -0.8865, -0.8721],\n",
      "         ...,\n",
      "         [-0.7292, -0.8386, -1.1242,  ..., -0.8128, -1.4685, -1.4599],\n",
      "         [-0.7243, -0.7390, -1.0519,  ..., -0.6838, -1.2370, -1.3971],\n",
      "         [-0.5838, -0.3992, -0.7835,  ..., -0.4860, -0.1854, -1.2545]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1852, -0.3911, -0.5262,  ...,  0.8941, -0.2581,  0.6346],\n",
      "         [-0.3240, -0.4216, -0.6218,  ...,  0.5630, -0.3970,  0.1895],\n",
      "         [-0.3894, -0.4114, -0.6524,  ...,  0.2492, -0.3309, -0.2671],\n",
      "         ...,\n",
      "         [-0.0888, -0.1612, -0.3535,  ...,  0.5286, -0.1722,  0.0868],\n",
      "         [-0.1035, -0.1957, -0.4552,  ...,  0.2965, -0.3904, -0.2443],\n",
      "         [-0.0920, -0.2202, -0.4834,  ...,  0.1632, -0.2648, -0.3984]],\n",
      "\n",
      "        [[ 0.1923,  0.2437,  1.3570,  ...,  0.1417,  1.2036,  1.3652],\n",
      "         [ 0.1824,  0.1318,  1.6180,  ...,  0.0600,  1.2234,  1.2339],\n",
      "         [ 0.2249,  0.1155,  1.3937,  ...,  0.1288,  1.0580,  1.3195],\n",
      "         ...,\n",
      "         [ 0.2021,  0.2213, -0.1243,  ..., -0.0647,  0.8993,  1.3538],\n",
      "         [ 0.1792,  0.2335,  0.2873,  ...,  0.1245,  1.0250,  1.5193],\n",
      "         [ 0.1514,  0.2844, -0.0680,  ...,  0.0643,  1.0977,  1.4223]],\n",
      "\n",
      "        [[ 5.2863,  5.0879,  1.3937,  ...,  1.0532,  0.8067,  0.5319],\n",
      "         [ 5.4889,  6.0624,  1.5346,  ...,  1.3627,  1.0845,  0.8458],\n",
      "         [ 2.2622,  4.8539,  0.9686,  ...,  1.0747,  1.0977,  0.5890],\n",
      "         ...,\n",
      "         [-0.5429, -0.3768, -0.7627,  ..., -0.4688,  0.1652, -1.2773],\n",
      "         [ 0.1269,  0.5408, -0.0435,  ..., -0.0733,  0.3702, -0.8664],\n",
      "         [ 1.0385,  1.8266,  1.1977,  ...,  0.4383,  0.3900, -0.1872]]],\n",
      "       dtype=torch.float64), tensor([[[ 0.1351, -0.2079,  0.1771,  ...,  0.4168,  1.1771,  1.5535],\n",
      "         [-0.0218, -0.3137, -0.4821,  ...,  0.3438,  1.0448,  1.3880],\n",
      "         [-0.1639, -0.2832, -0.4858,  ...,  0.0256,  0.3768,  1.0969],\n",
      "         ...,\n",
      "         [ 0.2805,  0.0484,  2.0333,  ...,  0.0170,  1.6070,  1.2967],\n",
      "         [ 0.1677,  0.1115,  1.9218,  ...,  0.0600,  1.6930,  1.2510],\n",
      "         [ 0.2658,  0.0911,  1.2259,  ...,  0.0213,  1.6401,  1.1768]],\n",
      "\n",
      "        [[ 0.2102,  1.1063,  0.1856,  ...,  1.2036,  1.0316,  0.6404],\n",
      "         [ 0.2184,  0.9049, -0.1133,  ...,  0.8339,  0.8596,  0.2694],\n",
      "         [ 0.1677,  0.4207, -0.1391,  ...,  1.1134,  0.7406,  0.5547],\n",
      "         ...,\n",
      "         [-0.7717, -0.7451, -1.0653,  ..., -1.8919, -1.2569, -1.4599],\n",
      "         [-0.6148, -0.4358, -0.7823,  ..., -1.7715, -0.1523, -1.2716],\n",
      "         [-0.0937,  0.4350, -0.2162,  ..., -1.4104,  0.4099, -0.9177]],\n",
      "\n",
      "        [[ 4.8648,  3.1978,  0.7248,  ...,  0.9199,  0.7273,  0.4920],\n",
      "         [ 4.6475,  2.7421,  1.0654,  ...,  1.3111,  0.7472,  0.7602],\n",
      "         [ 1.3865,  4.2781,  0.5863,  ...,  0.8468,  0.6612,  0.2351],\n",
      "         ...,\n",
      "         [-0.7292, -0.8203, -1.0984,  ..., -0.7311, -1.4354, -1.4028],\n",
      "         [-0.7276, -0.8041, -1.1131,  ..., -0.7741, -1.4751, -1.4257],\n",
      "         [-0.7210, -0.7064, -1.0482,  ..., -0.6709, -1.2238, -1.3515]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3387, -0.2995,  3.0172,  ...,  0.5286, -0.2648,  0.1724],\n",
      "         [-0.5054, -0.4134, -0.6892,  ...,  0.2105, -0.5492, -0.1929],\n",
      "         [-0.7112, -0.5965, -0.8093,  ..., -0.1292, -0.8336, -0.5981],\n",
      "         ...,\n",
      "         [ 0.1775, -0.1693,  0.1452,  ...,  1.2552,  0.7406,  1.0912],\n",
      "         [ 0.1563, -0.1917, -0.3559,  ...,  1.0962,  0.7935,  0.8972],\n",
      "         [-0.0561, -0.3158, -0.4343,  ...,  1.0188,  0.1652,  0.7659]],\n",
      "\n",
      "        [[ 0.1416, -0.0676,  2.6435,  ...,  1.5863,  0.9919,  1.5421],\n",
      "         [ 0.0730, -0.2405,  1.7956,  ...,  1.2122,  0.9059,  1.2339],\n",
      "         [ 0.0926, -0.1998,  0.7456,  ...,  1.4186,  0.6612,  1.5022],\n",
      "         ...,\n",
      "         [ 0.2102,  0.3638,  1.1144,  ...,  0.0256,  1.2499,  1.4508],\n",
      "         [ 0.2445,  0.2742,  1.6167,  ...,  0.2406,  1.3623,  1.8218],\n",
      "         [ 0.1988,  0.3454,  1.6621,  ...,  0.3395,  1.1969,  1.9587]],\n",
      "\n",
      "        [[ 0.3115, -0.0289,  0.3167,  ...,  0.7737,  0.5091,  0.0354],\n",
      "         [ 0.3556, -0.0309,  1.2798,  ...,  0.8382,  0.4231,  0.2123],\n",
      "         [ 0.2805, -0.0187,  0.2984,  ...,  0.9629,  0.6149,  0.5433],\n",
      "         ...,\n",
      "         [-0.5037, -0.4094, -0.7456,  ..., -0.4258,  0.1850, -1.1860],\n",
      "         [ 0.0910,  0.5509, -0.0570,  ...,  0.0557,  0.3702, -0.7808],\n",
      "         [ 1.7035,  1.0128,  1.4575,  ...,  0.3825,  0.3834, -0.1244]]],\n",
      "       dtype=torch.float64), tensor([[[ 0.1957, -0.3333,  0.5000,  0.3301],\n",
      "         [ 0.2391, -0.3333,  0.5000,  0.3301],\n",
      "         [ 0.2826, -0.3333,  0.5000,  0.3301],\n",
      "         ...,\n",
      "         [ 0.0652,  0.3333, -0.4000,  0.3411],\n",
      "         [ 0.1087,  0.3333, -0.4000,  0.3411],\n",
      "         [ 0.1522,  0.3333, -0.4000,  0.3411]],\n",
      "\n",
      "        [[-0.1522, -0.1667, -0.2333,  0.1027],\n",
      "         [-0.1087, -0.1667, -0.2333,  0.1027],\n",
      "         [-0.0652, -0.1667, -0.2333,  0.1027],\n",
      "         ...,\n",
      "         [-0.2826,  0.5000, -0.1000,  0.1137],\n",
      "         [-0.2391,  0.5000, -0.1000,  0.1137],\n",
      "         [-0.1957,  0.5000, -0.1000,  0.1137]],\n",
      "\n",
      "        [[-0.2391, -0.5000,  0.1667,  0.3904],\n",
      "         [-0.1957, -0.5000,  0.1667,  0.3904],\n",
      "         [-0.1522, -0.5000,  0.1667,  0.3904],\n",
      "         ...,\n",
      "         [-0.3696,  0.1667,  0.3000,  0.4014],\n",
      "         [-0.3261,  0.1667,  0.3000,  0.4014],\n",
      "         [-0.2826,  0.1667,  0.3000,  0.4014]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3696, -0.1667,  0.4000,  0.4918],\n",
      "         [ 0.4130, -0.1667,  0.4000,  0.4918],\n",
      "         [ 0.4565, -0.1667,  0.4000,  0.4918],\n",
      "         ...,\n",
      "         [ 0.2391,  0.5000, -0.5000, -0.5000],\n",
      "         [ 0.2826,  0.5000, -0.5000, -0.5000],\n",
      "         [ 0.3261,  0.5000, -0.5000, -0.5000]],\n",
      "\n",
      "        [[ 0.1522,  0.5000,  0.2667,  0.2288],\n",
      "         [ 0.1957,  0.5000,  0.2667,  0.2288],\n",
      "         [ 0.2391,  0.5000,  0.2667,  0.2288],\n",
      "         ...,\n",
      "         [ 0.0217,  0.0000,  0.4000,  0.2397],\n",
      "         [ 0.0652,  0.0000,  0.4000,  0.2397],\n",
      "         [ 0.1087,  0.0000,  0.4000,  0.2397]],\n",
      "\n",
      "        [[-0.1087,  0.1667, -0.1333, -0.1411],\n",
      "         [-0.0652,  0.1667, -0.1333, -0.1411],\n",
      "         [-0.0217,  0.1667, -0.1333, -0.1411],\n",
      "         ...,\n",
      "         [-0.2391, -0.3333,  0.0000, -0.1301],\n",
      "         [-0.1957, -0.3333,  0.0000, -0.1301],\n",
      "         [-0.1522, -0.3333,  0.0000, -0.1301]]], dtype=torch.float64), tensor([[[ 0.2826,  0.1667,  0.4333,  0.2425],\n",
      "         [ 0.3261,  0.1667,  0.4333,  0.2425],\n",
      "         [ 0.3696,  0.1667,  0.4333,  0.2425],\n",
      "         ...,\n",
      "         [ 0.0652, -0.5000, -0.3333,  0.3466],\n",
      "         [ 0.1087, -0.5000, -0.3333,  0.3466],\n",
      "         [ 0.1522, -0.5000, -0.3333,  0.3466]],\n",
      "\n",
      "        [[-0.0652,  0.3333, -0.2667,  0.0151],\n",
      "         [-0.0217,  0.3333, -0.2667,  0.0151],\n",
      "         [ 0.0217,  0.3333, -0.2667,  0.0151],\n",
      "         ...,\n",
      "         [-0.2826, -0.3333, -0.0333,  0.1192],\n",
      "         [-0.2391, -0.3333, -0.0333,  0.1192],\n",
      "         [-0.1957, -0.3333, -0.0333,  0.1192]],\n",
      "\n",
      "        [[-0.1522,  0.0000,  0.1333,  0.3027],\n",
      "         [-0.1087,  0.0000,  0.1333,  0.3027],\n",
      "         [-0.0652,  0.0000,  0.1333,  0.3027],\n",
      "         ...,\n",
      "         [-0.3696,  0.5000,  0.3667,  0.4068],\n",
      "         [-0.3261,  0.5000,  0.3667,  0.4068],\n",
      "         [-0.2826,  0.5000,  0.3667,  0.4068]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4565,  0.3333,  0.3333,  0.4041],\n",
      "         [ 0.5000,  0.3333,  0.3333,  0.4041],\n",
      "         [-0.5000,  0.5000,  0.3667,  0.4068],\n",
      "         ...,\n",
      "         [ 0.2391, -0.3333, -0.4333, -0.4945],\n",
      "         [ 0.2826, -0.3333, -0.4333, -0.4945],\n",
      "         [ 0.3261, -0.3333, -0.4333, -0.4945]],\n",
      "\n",
      "        [[ 0.2391, -0.1667,  0.2333,  0.1411],\n",
      "         [ 0.2826, -0.1667,  0.2333,  0.1411],\n",
      "         [ 0.3261, -0.1667,  0.2333,  0.1411],\n",
      "         ...,\n",
      "         [ 0.0217,  0.3333,  0.4667,  0.2452],\n",
      "         [ 0.0652,  0.3333,  0.4667,  0.2452],\n",
      "         [ 0.1087,  0.3333,  0.4667,  0.2452]],\n",
      "\n",
      "        [[-0.0217, -0.5000, -0.2000, -0.2288],\n",
      "         [ 0.0217, -0.5000, -0.2000, -0.2288],\n",
      "         [ 0.0652, -0.5000, -0.2000, -0.2288],\n",
      "         ...,\n",
      "         [-0.2391,  0.0000,  0.0667, -0.1247],\n",
      "         [-0.1957,  0.0000,  0.0667, -0.1247],\n",
      "         [-0.1522,  0.0000,  0.0667, -0.1247]]], dtype=torch.float64)]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 171, in collate_numpy_array_fn\n    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 161, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[0;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 264, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 142, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 171, in collate_numpy_array_fn\n    return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 119, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Yohan\\anaconda3\\envs\\tcitransformer\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 161, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "source": [
    "for j in data_loader:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "40b73ffc-5e23-4d81-ad25-86a1e34b064f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 96, 862])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a38486a8-2676-449e-8265-a3523437efb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7276, -0.8122, -1.0874,  ..., -0.8773, -1.4619, -1.6825],\n",
       "         [-0.7259, -0.7105, -1.0506,  ..., -0.8773, -1.3098, -1.6825],\n",
       "         [-0.7210, -0.4216, -0.7786,  ..., -0.5032, -0.3706, -1.5912],\n",
       "         ...,\n",
       "         [-0.7243, -0.6820, -0.9808,  ..., -0.4301, -1.2106, -1.0490],\n",
       "         [-0.7292, -0.8142, -1.0923,  ..., -0.8515, -1.3759, -1.6197],\n",
       "         [-0.7292, -0.8386, -1.1119,  ..., -0.8945, -1.4553, -1.6825]],\n",
       "\n",
       "        [[-0.5952, -0.4806, -0.7333,  ...,  0.0428, -0.5955, -0.3927],\n",
       "         [-0.7210, -0.6372, -0.9183,  ..., -0.2453, -0.9328, -0.7180],\n",
       "         [-0.7243, -0.7430, -1.0323,  ..., -0.4817, -1.2965, -1.0090],\n",
       "         ...,\n",
       "         [-0.2897, -0.4175, -0.6292,  ...,  0.8511, -0.2581,  0.6632],\n",
       "         [-0.3992, -0.4907, -0.7149,  ...,  0.3911, -0.5227,  0.0696],\n",
       "         [-0.5576, -0.5375, -0.7713,  ..., -0.0303, -0.7211, -0.2728]],\n",
       "\n",
       "        [[ 0.1432, -0.0309, -0.2383,  ..., -0.6150,  0.4826,  1.0513],\n",
       "         [ 0.1008,  0.0667, -0.2469,  ..., -0.5892,  0.5355,  0.9714],\n",
       "         [ 0.1253, -0.0940, -0.2775,  ..., -0.3828,  0.4760,  1.3823],\n",
       "         ...,\n",
       "         [ 0.1824,  0.4248,  0.2089,  ..., -0.5677,  0.5686,  0.4292],\n",
       "         [ 0.1465, -0.1164, -0.2064,  ..., -0.6279,  0.6546,  0.5262],\n",
       "         [ 0.1547,  0.1990, -0.1979,  ..., -0.5935,  8.3268,  0.8915]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1204,  0.0220,  0.9404,  ...,  1.3713,  0.6017,  1.2111],\n",
       "         [ 0.1775, -0.0737,  0.8681,  ...,  1.3971,  0.7869,  1.2853],\n",
       "         [ 0.1024, -0.1713,  0.7799,  ...,  1.3627,  0.7604,  1.3538],\n",
       "         ...,\n",
       "         [ 0.2086,  0.2315,  0.9441,  ...,  1.4143,  0.9456,  1.0342],\n",
       "         [ 0.1677,  0.1135,  1.5873,  ...,  1.4960,  0.8001,  1.2111],\n",
       "         [ 0.2494,  0.2641,  1.8361,  ...,  1.4960,  0.7340,  1.3880]],\n",
       "\n",
       "        [[-0.7259, -0.7369, -1.0445,  ..., -0.5204, -1.2635, -1.1175],\n",
       "         [-0.7259, -0.8305, -1.1021,  ..., -0.6924, -1.3957, -1.3172],\n",
       "         [-0.7259, -0.8325, -1.1303,  ..., -0.7698, -1.5214, -1.4314],\n",
       "         ...,\n",
       "         [-0.5119, -0.5172, -0.7603,  ...,  0.3395, -0.5822,  0.1039],\n",
       "         [-0.7210, -0.6291, -0.8669,  ..., -0.1894, -0.9791, -0.6666],\n",
       "         [-0.7243, -0.7654, -1.0151,  ..., -0.4817, -1.2965, -1.0262]],\n",
       "\n",
       "        [[-0.6312, -0.4094, -0.7456,  ..., -0.4473, -0.1060, -1.2716],\n",
       "         [ 0.0566,  0.4024, -0.0778,  ..., -0.0690,  0.2048, -0.8492],\n",
       "         [ 0.6187,  1.4339,  0.7836,  ...,  0.3481,  0.5157, -0.3413],\n",
       "         ...,\n",
       "         [-0.7276, -0.8061, -1.0702,  ..., -0.6666, -1.3428, -1.2944],\n",
       "         [-0.7227, -0.8366, -1.1291,  ..., -0.7827, -1.5016, -1.4143],\n",
       "         [-0.7292, -0.8386, -1.1450,  ..., -0.7999, -1.5214, -1.4428]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "802464be-aa72-4bc9-9718-ac3e138aa12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch_x = model(batch_x.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "21166c4b-dbd7-45a9-9338-9ed44afd3451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.8976, -3.8651, -3.8973, -3.8762, -3.8460, -3.8665, -3.8788, -3.8616,\n",
       "         -3.8501, -3.8865, -3.8442, -3.8622, -3.8551, -3.8669, -3.8404, -3.8483,\n",
       "         -3.8980, -3.8845, -3.9017, -3.8448, -3.8482, -3.8548, -3.8698, -3.8599,\n",
       "         -3.9028, -3.8988, -3.8533, -3.9033, -3.9049, -3.9087, -3.8803, -3.8805,\n",
       "         -3.8523, -3.8511, -3.8595, -3.8389, -3.8660, -3.9047, -3.8587, -3.8903,\n",
       "         -3.8524, -3.8560, -3.8717, -3.8948, -3.8419, -3.9010, -3.8984, -3.8538],\n",
       "        [-3.9004, -3.8643, -3.9040, -3.8727, -3.8473, -3.8692, -3.8825, -3.8588,\n",
       "         -3.8474, -3.8891, -3.8402, -3.8575, -3.8542, -3.8712, -3.8400, -3.8451,\n",
       "         -3.8964, -3.8830, -3.9052, -3.8451, -3.8529, -3.8518, -3.8694, -3.8594,\n",
       "         -3.9028, -3.8975, -3.8520, -3.9052, -3.9034, -3.9144, -3.8811, -3.8775,\n",
       "         -3.8495, -3.8461, -3.8628, -3.8404, -3.8646, -3.9132, -3.8604, -3.8901,\n",
       "         -3.8527, -3.8479, -3.8718, -3.8919, -3.8414, -3.9006, -3.9026, -3.8531],\n",
       "        [-3.9004, -3.8593, -3.8921, -3.8736, -3.8431, -3.8639, -3.8785, -3.8616,\n",
       "         -3.8442, -3.8886, -3.8439, -3.8591, -3.8590, -3.8694, -3.8421, -3.8432,\n",
       "         -3.8925, -3.8832, -3.8984, -3.8433, -3.8530, -3.8511, -3.8696, -3.8678,\n",
       "         -3.9034, -3.9061, -3.8526, -3.9026, -3.9004, -3.9132, -3.8821, -3.8759,\n",
       "         -3.8505, -3.8591, -3.8635, -3.8402, -3.8677, -3.9092, -3.8560, -3.8932,\n",
       "         -3.8517, -3.8533, -3.8663, -3.8967, -3.8435, -3.9027, -3.9033, -3.8555],\n",
       "        [-3.9002, -3.8681, -3.8904, -3.8751, -3.8400, -3.8673, -3.8836, -3.8586,\n",
       "         -3.8501, -3.8906, -3.8414, -3.8598, -3.8514, -3.8703, -3.8451, -3.8463,\n",
       "         -3.8948, -3.8813, -3.9051, -3.8441, -3.8489, -3.8522, -3.8745, -3.8649,\n",
       "         -3.9046, -3.8947, -3.8497, -3.9070, -3.9034, -3.9148, -3.8782, -3.8700,\n",
       "         -3.8488, -3.8474, -3.8623, -3.8430, -3.8678, -3.9085, -3.8635, -3.8904,\n",
       "         -3.8529, -3.8566, -3.8700, -3.8950, -3.8452, -3.9021, -3.8990, -3.8506],\n",
       "        [-3.8991, -3.8648, -3.8966, -3.8757, -3.8414, -3.8633, -3.8799, -3.8630,\n",
       "         -3.8480, -3.8851, -3.8460, -3.8660, -3.8557, -3.8717, -3.8376, -3.8465,\n",
       "         -3.8941, -3.8888, -3.8986, -3.8450, -3.8485, -3.8492, -3.8727, -3.8653,\n",
       "         -3.9035, -3.9006, -3.8560, -3.9034, -3.9003, -3.9051, -3.8841, -3.8792,\n",
       "         -3.8500, -3.8457, -3.8592, -3.8423, -3.8732, -3.9075, -3.8605, -3.8921,\n",
       "         -3.8531, -3.8512, -3.8736, -3.8923, -3.8429, -3.8999, -3.8976, -3.8530],\n",
       "        [-3.9028, -3.8643, -3.8985, -3.8729, -3.8458, -3.8659, -3.8808, -3.8623,\n",
       "         -3.8519, -3.8881, -3.8414, -3.8601, -3.8508, -3.8648, -3.8421, -3.8489,\n",
       "         -3.8945, -3.8915, -3.9013, -3.8493, -3.8477, -3.8502, -3.8729, -3.8644,\n",
       "         -3.9026, -3.9028, -3.8499, -3.9056, -3.9002, -3.9109, -3.8749, -3.8752,\n",
       "         -3.8485, -3.8539, -3.8588, -3.8427, -3.8680, -3.9036, -3.8567, -3.8964,\n",
       "         -3.8505, -3.8587, -3.8700, -3.8890, -3.8451, -3.9016, -3.8971, -3.8529],\n",
       "        [-3.9025, -3.8625, -3.8957, -3.8764, -3.8463, -3.8646, -3.8826, -3.8597,\n",
       "         -3.8477, -3.8877, -3.8490, -3.8615, -3.8483, -3.8724, -3.8382, -3.8457,\n",
       "         -3.8963, -3.8840, -3.9015, -3.8477, -3.8501, -3.8539, -3.8676, -3.8612,\n",
       "         -3.9033, -3.8991, -3.8468, -3.9072, -3.8978, -3.9096, -3.8789, -3.8764,\n",
       "         -3.8547, -3.8491, -3.8607, -3.8430, -3.8662, -3.9109, -3.8601, -3.8903,\n",
       "         -3.8500, -3.8615, -3.8683, -3.8952, -3.8421, -3.8991, -3.9001, -3.8560],\n",
       "        [-3.9022, -3.8635, -3.8975, -3.8759, -3.8435, -3.8674, -3.8828, -3.8655,\n",
       "         -3.8517, -3.8794, -3.8454, -3.8641, -3.8520, -3.8677, -3.8424, -3.8504,\n",
       "         -3.8927, -3.8835, -3.9043, -3.8487, -3.8441, -3.8477, -3.8735, -3.8660,\n",
       "         -3.9049, -3.8963, -3.8483, -3.9026, -3.8990, -3.9122, -3.8805, -3.8771,\n",
       "         -3.8491, -3.8530, -3.8532, -3.8394, -3.8715, -3.9113, -3.8595, -3.8939,\n",
       "         -3.8487, -3.8569, -3.8691, -3.8976, -3.8449, -3.8999, -3.8968, -3.8517],\n",
       "        [-3.9026, -3.8652, -3.8946, -3.8793, -3.8475, -3.8614, -3.8827, -3.8642,\n",
       "         -3.8497, -3.8834, -3.8421, -3.8629, -3.8492, -3.8777, -3.8365, -3.8454,\n",
       "         -3.9004, -3.8923, -3.9032, -3.8433, -3.8532, -3.8527, -3.8663, -3.8657,\n",
       "         -3.9053, -3.9013, -3.8492, -3.9032, -3.9015, -3.9096, -3.8778, -3.8800,\n",
       "         -3.8542, -3.8512, -3.8619, -3.8404, -3.8638, -3.9093, -3.8587, -3.8877,\n",
       "         -3.8449, -3.8612, -3.8658, -3.8882, -3.8458, -3.9009, -3.8961, -3.8502],\n",
       "        [-3.8984, -3.8657, -3.8939, -3.8750, -3.8425, -3.8663, -3.8815, -3.8587,\n",
       "         -3.8511, -3.8873, -3.8473, -3.8561, -3.8528, -3.8712, -3.8439, -3.8471,\n",
       "         -3.8979, -3.8942, -3.9052, -3.8475, -3.8441, -3.8528, -3.8717, -3.8594,\n",
       "         -3.9025, -3.9041, -3.8481, -3.9100, -3.8962, -3.9097, -3.8854, -3.8755,\n",
       "         -3.8440, -3.8487, -3.8555, -3.8434, -3.8700, -3.9062, -3.8582, -3.8897,\n",
       "         -3.8514, -3.8586, -3.8682, -3.8925, -3.8442, -3.8973, -3.8988, -3.8593],\n",
       "        [-3.9049, -3.8653, -3.9002, -3.8733, -3.8413, -3.8622, -3.8817, -3.8601,\n",
       "         -3.8531, -3.8838, -3.8447, -3.8626, -3.8545, -3.8750, -3.8385, -3.8469,\n",
       "         -3.9016, -3.8877, -3.9019, -3.8432, -3.8507, -3.8521, -3.8697, -3.8672,\n",
       "         -3.9045, -3.9010, -3.8502, -3.9034, -3.8974, -3.9133, -3.8841, -3.8786,\n",
       "         -3.8448, -3.8502, -3.8575, -3.8452, -3.8639, -3.9096, -3.8518, -3.8906,\n",
       "         -3.8489, -3.8550, -3.8707, -3.8914, -3.8478, -3.9012, -3.9033, -3.8434],\n",
       "        [-3.8933, -3.8631, -3.8991, -3.8755, -3.8466, -3.8648, -3.8869, -3.8612,\n",
       "         -3.8469, -3.8877, -3.8449, -3.8621, -3.8495, -3.8722, -3.8445, -3.8437,\n",
       "         -3.8992, -3.8857, -3.9026, -3.8432, -3.8485, -3.8513, -3.8710, -3.8666,\n",
       "         -3.9073, -3.9019, -3.8495, -3.9061, -3.8952, -3.9099, -3.8835, -3.8787,\n",
       "         -3.8476, -3.8492, -3.8605, -3.8434, -3.8652, -3.9033, -3.8630, -3.8880,\n",
       "         -3.8542, -3.8554, -3.8689, -3.8900, -3.8437, -3.8985, -3.9003, -3.8556],\n",
       "        [-3.8995, -3.8626, -3.9027, -3.8765, -3.8419, -3.8624, -3.8824, -3.8603,\n",
       "         -3.8481, -3.8903, -3.8406, -3.8604, -3.8522, -3.8715, -3.8457, -3.8459,\n",
       "         -3.8955, -3.8828, -3.9038, -3.8445, -3.8481, -3.8503, -3.8705, -3.8624,\n",
       "         -3.9085, -3.8985, -3.8498, -3.9104, -3.8996, -3.9099, -3.8812, -3.8754,\n",
       "         -3.8460, -3.8567, -3.8617, -3.8454, -3.8635, -3.9086, -3.8561, -3.8912,\n",
       "         -3.8475, -3.8631, -3.8663, -3.8929, -3.8459, -3.8949, -3.8984, -3.8569],\n",
       "        [-3.8994, -3.8626, -3.8975, -3.8729, -3.8474, -3.8597, -3.8799, -3.8620,\n",
       "         -3.8530, -3.8875, -3.8447, -3.8607, -3.8507, -3.8760, -3.8401, -3.8501,\n",
       "         -3.8950, -3.8882, -3.9027, -3.8418, -3.8509, -3.8504, -3.8737, -3.8617,\n",
       "         -3.9049, -3.8978, -3.8432, -3.9006, -3.8965, -3.9084, -3.8833, -3.8777,\n",
       "         -3.8497, -3.8525, -3.8590, -3.8455, -3.8721, -3.9099, -3.8598, -3.8883,\n",
       "         -3.8520, -3.8580, -3.8702, -3.8963, -3.8423, -3.9020, -3.8961, -3.8539],\n",
       "        [-3.8989, -3.8658, -3.8937, -3.8765, -3.8432, -3.8640, -3.8836, -3.8571,\n",
       "         -3.8487, -3.8928, -3.8433, -3.8620, -3.8528, -3.8722, -3.8428, -3.8469,\n",
       "         -3.8941, -3.8866, -3.9060, -3.8409, -3.8519, -3.8547, -3.8711, -3.8668,\n",
       "         -3.9003, -3.8997, -3.8532, -3.9052, -3.8959, -3.9147, -3.8765, -3.8781,\n",
       "         -3.8483, -3.8542, -3.8586, -3.8422, -3.8675, -3.9032, -3.8547, -3.8899,\n",
       "         -3.8492, -3.8613, -3.8709, -3.8910, -3.8433, -3.9036, -3.8997, -3.8517],\n",
       "        [-3.8999, -3.8703, -3.8946, -3.8697, -3.8444, -3.8656, -3.8823, -3.8589,\n",
       "         -3.8550, -3.8880, -3.8446, -3.8609, -3.8555, -3.8646, -3.8414, -3.8451,\n",
       "         -3.8956, -3.8860, -3.9015, -3.8449, -3.8530, -3.8465, -3.8743, -3.8653,\n",
       "         -3.9012, -3.9039, -3.8545, -3.8994, -3.8991, -3.9104, -3.8843, -3.8798,\n",
       "         -3.8520, -3.8492, -3.8600, -3.8420, -3.8660, -3.9049, -3.8604, -3.8973,\n",
       "         -3.8508, -3.8560, -3.8650, -3.8893, -3.8455, -3.9045, -3.8950, -3.8502]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batch_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
