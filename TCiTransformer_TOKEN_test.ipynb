{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d5f8d8-e465-485a-a418-2fc525fdc7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import numpy as np\n",
    "\n",
    "PEMS03_path = './dataset/PEMS/PEMS03.npz'\n",
    "\n",
    "origin_data = np.load(PEMS03_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69eefbfa-a443-417b-a1f7-b2987b2b5081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26208, 358, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ca22a7-9027-4a39-b00b-1e68364d9d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(origin_data['data'].shape[0]*0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fba4f79-2df3-4070-98a9-aae391e4a06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15724"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e70335-d26c-4f36-9f07-b01ff4ad0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = []\n",
    "for j in range(200):\n",
    "    train_tokens.append(origin_data['data'][j:j+108, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6575f97f-d933-4db1-9a9e-baf8d18ce998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 358)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb3f10cd-efc3-41ca-ba43-06566204f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itransformer_tcn 학습\n",
    "from model import iTransformer_TCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbd363e4-658f-4c0d-acca-a39c781ee6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers.Transformer_EncDec import Encoder, EncoderLayer\n",
    "from layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
    "from layers.Embed import DataEmbedding_inverted_TCN\n",
    "\n",
    "parser = argparse.ArgumentParser(description='iTransformerTCN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a98a388a-3142-48ed-a1dd-8b60cae6542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--pred_len'], dest='pred_len', nargs=None, const=None, default=96, type=<class 'int'>, choices=None, required=False, help='prediction sequence length', metavar=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parser.add_argument('--model_id', type=str, default='test', help='model id')\n",
    "parser.add_argument('--model', type=str, default='iTransformer_TCN',\n",
    "                        help='model name, options: [iTransformer, iInformer, iReformer, iFlowformer, iFlashformer, iTransformer_TCN]')\n",
    "parser.add_argument('--data', type=str, default='custom', help='dataset type')\n",
    "parser.add_argument('--root_path', type=str, default='./data/electricity/', help='root path of the data file')\n",
    "parser.add_argument('--data_path', type=str, default='electricity.csv', help='data csv file')\n",
    "parser.add_argument('--features', type=str, default='M',\n",
    "                    help='forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate')\n",
    "parser.add_argument('--target', type=str, default='OT', help='target feature in S or MS task')\n",
    "parser.add_argument('--freq', type=str, default='h',\n",
    "                    help='freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h')\n",
    "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location of model checkpoints')\n",
    "parser.add_argument('--train_ratio', type=float, default=0.7, help='train data ratio')\n",
    "parser.add_argument('--test_ratio', type=float, default=0.2, help='test data ratio')\n",
    "# parser.add_argument('--select_ratio', type=float, default=1.0, help='select data ratio')\n",
    "parser.add_argument('--two_sided', action='store_true', default=False, help='whether selecting train data as two-sided')\n",
    "parser.add_argument('--train_step', type=float, default=1.0, help='train data with certain stes. for example train_step=2 means only train even number of data')\n",
    "\n",
    "# forecasting task\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='input sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='start token length') # no longer needed in inverted Transformers\n",
    "parser.add_argument('--pred_len', type=int, default=96, help='prediction sequence length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a772b910-0430-4458-bffc-5b7dee73d5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--augmented_token'], dest='augmented_token', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='Use augmented input token with 0 with pred_len instead of usual input token', metavar=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iTransformer\n",
    "parser.add_argument('--exp_name', type=str, required=False, default='MTSF',\n",
    "                    help='experiemnt name, options:[MTSF, partial_train]')\n",
    "parser.add_argument('--channel_independence', action='store_true', default=False, help='whether to use channel_independence mechanism')\n",
    "parser.add_argument('--inverse', action='store_true', help='inverse output data', default=False)\n",
    "parser.add_argument('--class_strategy', type=str, default='projection', help='projection/average/cls_token')\n",
    "parser.add_argument('--target_root_path', type=str, default='./data/electricity/', help='root path of the data file')\n",
    "parser.add_argument('--target_data_path', type=str, default='electricity.csv', help='data file')\n",
    "parser.add_argument('--efficient_training', action='store_true', default=False, help='whether to use efficient_training (exp_name should be partial train)') # See Figure 8 of our paper for the detail\n",
    "parser.add_argument('--use_norm', type=int, default=1, help='use norm and denorm')\n",
    "parser.add_argument('--partial_start_index', type=int, default=0, help='the start index of variates for partial training, '\n",
    "                                                                       'you can select [partial_start_index, min(enc_in + partial_start_index, N)]')\n",
    "\n",
    "# tcitransformer\n",
    "parser.add_argument('--tcn_layers', type=int, default=3, help='number of layers of TCN embedding field')\n",
    "parser.add_argument('--tcn_kernel_size', type=int, default=2, help='number of kernel size of TCN embedding field')\n",
    "parser.add_argument('--tcn_dropout', type=float, default=0.1, help='dropout rate of TCN embedding field')\n",
    "parser.add_argument('--tcn_uniform_layer', action='store_false', help='whether tcn_layer size is uniform', default=True)\n",
    "parser.add_argument('--tcn_bias', action='store_false', help='Use Bias in TCN Layers', default=True)\n",
    "parser.add_argument('--augmented_token', action='store_true', help='Use augmented input token with 0 with pred_len instead of usual input token', default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "946078be-576b-4c92-9e93-4f8bdc702560",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = ['--pred_len', '12', '--label_len', '12']\n",
    "args = parser.parse_args(tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5771c342-c500-4e81-acae-08c69bdd0164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(is_training=1, model_id='test', model='iTransformer_TCN', data='custom', root_path='./data/electricity/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', train_ratio=0.7, test_ratio=0.2, two_sided=False, train_step=1.0, seq_len=96, label_len=12, pred_len=12, exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=1, partial_start_index=0, tcn_layers=3, tcn_kernel_size=2, tcn_dropout=0.1, tcn_uniform_layer=True, tcn_bias=True, augmented_token=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b86eea1-27c8-44b7-93bd-dc5120d5b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.output_attention= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c1d8826-c37e-4c59-9e41-b75fcb64757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.d_model = 512\n",
    "args.embed = 'timeF'\n",
    "args.dropout= 0.05\n",
    "args.e_layers = 3\n",
    "args.factor = 1\n",
    "args.n_heads = 16\n",
    "args.d_ff = 512\n",
    "args.activation= 'gelu'\n",
    "args.output_attention=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aad9600e-a72c-41ea-8e6e-a78285018d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:: 96 12\n"
     ]
    }
   ],
   "source": [
    "model = iTransformer_TCN.Model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75abeeba-2e85-47a9-a81d-7eb713e2b4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (enc_embedding): DataEmbedding_inverted_TCN(\n",
       "    (value_embedding): TemporalConvNet(\n",
       "      (network): Sequential(\n",
       "        (0): TemporalBlock(\n",
       "          (conv1): Conv1d(96, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (chomp1): Chomp1d()\n",
       "          (relu1): ReLU()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "          (chomp2): Chomp1d()\n",
       "          (relu2): ReLU()\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (net): Sequential(\n",
       "            (0): Conv1d(96, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "            (1): Chomp1d()\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "            (5): Chomp1d()\n",
       "            (6): ReLU()\n",
       "            (7): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (downsample): Conv1d(96, 512, kernel_size=(1,), stride=(1,))\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): TemporalBlock(\n",
       "          (conv1): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (chomp1): Chomp1d()\n",
       "          (relu1): ReLU()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (chomp2): Chomp1d()\n",
       "          (relu2): ReLU()\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (net): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (1): Chomp1d()\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "            (5): Chomp1d()\n",
       "            (6): ReLU()\n",
       "            (7): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): TemporalBlock(\n",
       "          (conv1): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (chomp1): Chomp1d()\n",
       "          (relu1): ReLU()\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (conv2): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (chomp2): Chomp1d()\n",
       "          (relu2): ReLU()\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (net): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "            (1): Chomp1d()\n",
       "            (2): ReLU()\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "            (4): Conv1d(512, 512, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "            (5): Chomp1d()\n",
       "            (6): ReLU()\n",
       "            (7): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.05, inplace=False)\n",
       "  )\n",
       "  (encoder): Encoder(\n",
       "    (attn_layers): ModuleList(\n",
       "      (0-2): 3 x EncoderLayer(\n",
       "        (attention): AttentionLayer(\n",
       "          (inner_attention): FullAttention(\n",
       "            (dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.05, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projector): Linear(in_features=512, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c06fbcf-cc32-475a-80f2-9b71833cf03d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'devices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevices\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'devices'"
     ]
    }
   ],
   "source": [
    "args.devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af8dd883-eec0-4e69-b932-b50b8b52f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_447075/1947692231.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  batch_x = torch.Tensor([train_tokens[0][:96, :], train_tokens[1][:96, :]] ).float().to('cpu')\n"
     ]
    }
   ],
   "source": [
    "batch_x = torch.Tensor([train_tokens[0][:96, :], train_tokens[1][:96, :]] ).float().to('cpu')\n",
    "batch_y = torch.Tensor([train_tokens[0][72:, :], train_tokens[1][72:, :]] ).float().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0a044d7-a4a7-4fa3-a033-396ee4c2856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mark_x = None\n",
    "batch_mark_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "542b495d-62a8-489c-81e4-9f3942586041",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = model(batch_x, batch_mark_x, batch_y, batch_mark_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e509098f-2a2b-4ce4-a061-99a8892a95d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 358])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07b24179-4aaa-447f-ba0b-7dbc156cf50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 36, 358])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0515d230-ccdc-4d63-a848-f973c6f291f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 89., 102., 112., 108., 110., 114., 110., 124., 110., 112., 139., 113.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y[0][24:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a63e6fc-0208-406c-9926-419088636e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 63.,  62.,  57.,  48.,  47.,  51.,  62.,  35.,  42.,  47.,  38.,  31.,\n",
       "         24.,  37.,  22.,  24.,  40.,  18.,  32.,  27.,  24.,  21.,  22.,  25.,\n",
       "         30.,  23.,  30.,  28.,  28.,  19.,  20.,  18.,  24.,  27.,  29.,  29.,\n",
       "         23.,  19.,  20.,  24.,  19.,  24.,  22.,  20.,  16.,  31.,  24.,  35.,\n",
       "         19.,  28.,  14.,  34.,  29.,  25.,  28.,  26.,  28.,  24.,  28.,  26.,\n",
       "         30.,  33.,  31.,  37.,  43.,  45.,  46.,  46.,  37.,  46.,  38.,  43.,\n",
       "         48.,  48.,  60.,  62.,  63.,  71.,  61.,  76.,  53.,  61.,  65.,  59.,\n",
       "         66.,  61.,  62.,  73.,  80.,  73.,  74.,  69.,  89., 101., 103., 109.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x[0, :,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f27f56bb-c745-4668-8b7c-84e95b19321f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.2433, 42.0601, 32.0897, 53.4160, 49.0016, 19.2137, 33.1631, 50.6903,\n",
       "        40.6617, 31.9379, 59.1217, 37.0965], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_model[0, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9808d54a-f63d-4b61-adcf-c0e5b068ffae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch_x\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "batch_x[0, :,-1].to_numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
